@string{JRSSb =    {Journal of the Royal Statistical Society, B}}
@string{PAMI =     {IEEE Transactions on Pattern Analysis and 
                   Machine Intelligence}}
@string{ieeecomp = {IEEE Computer Society Press}}
@string{pCVPR =    {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition}}
@string{iccv =     {IEEE International Conference on Computer Vision (ICCV)}}
@string{mit =      {MIT Press}}
@InProceedings{Lawrence:backconstraints06,
  author =	 {Neil D. Lawrence and Joaquin {Qui\~nonero Candela}},
  title =	 {Local Distance Preservation in the {GP-LVM} through
                  Back Constraints},
  pages =	 {513--520},
  crossref =	 {Cohen:icml06},
  doi =		 {10.1145/1143844.1143909},
  year =	 2006,
  linkpdf =	 shefftp # {backConstraints.pdf},
  linksoftware = softwarehttp # {fgplvm/},
  group =	 {gplvm,dimensional reduction},
  errata1 =      {Equation (3) is missing integration over $\mathbf{f}$.},
  errataCredit1 = {Laurens van der Maaten},
  errata2 =      {Equation after Equation (5), the $v_{ij}$ should be inside the sum sign.},

  abstract =	 {The Gaussian process latent variable model (GP-LVM)
                  is a generative approach to non-linear low
                  dimensional embedding, that provides a smooth
                  probabilistic mapping from latent to data space. It
                  is also a non-linear generalization of probabilistic
                  PCA (PPCA) \cite{Tipping:probpca99}. While most
                  approaches to non-linear dimensionality methods
                  focus on preserving local distances in data space,
                  the GP-LVM focusses on exactly the opposite. Being a
                  smooth mapping from latent to data space, it
                  focusses on keeping things apart in latent space
                  that are far apart in data space. In this paper we
                  first provide an overview of dimensionality
                  reduction techniques, placing the emphasis on the
                  kind of distance relation preserved. We then show
                  how the GP-LVM can be generalized, through back
                  constraints, to additionally preserve local
                  distances. We give illustrative experiments on
                  common data sets.}
}

@InProceedings{Awasthi:image07,
  author =	 {Prajal Awasthi and Aakanksaha Gagrani and Balaraman
                  Ravindran},
  title =	 {Image Modelling using Tree Structured Conditional
                  Random Fields},
  OPTcrossref =	 {},
  OPTkey =	 {},
  booktitle =	 {Proceedings of the 20th International Joint
                  Conference on Artificial Intelligence (IJCAI 2007)},
  pages =	 {2060--2065},
  year =	 2007,
  editor =	 {Manuela M. Veloso},
  OPTvolume =	 {},
  OPTnumber =	 {},
  OPTseries =	 {},
  OPTaddress =	 {},
  OPTmonth =	 {},
  OPTorganization ={},
  OPTpublisher = {},
  OPTnote =	 {},
  OPTannote =	 {},
  OPTpubmedid =	 {},
  linkpdf =
                  {http://www.ijcai.org/papers07/Papers/IJCAI07-332.pdf},
  OPTlinksoftware ={},
  abstract =	 {In this paper we present a discriminative framework
                  based on conditional random fields for stochastic
                  modeling of images in a hierarchical fashion. The
                  main advantage of the proposed framework is its
                  ability to incorporate a rich set of interactions
                  among the image sites. We achieve this by inducing a
                  hierarchy of hidden variables over the given label
                  field. The proposed tree like structure of our model
                  eliminates the need for a huge parameter space and
                  at the same time permits the use of exact and
                  efficient inference procedures based on belief
                  propagation. We demonstrate the generality of our
                  approach by applying it to two important computer
                  vision tasks, namely image labeling and object
                  detection. The model parameters are trained using
                  the contrastive divergence algorithm. We report the
                  performance on real world images and compare it with
                  the existing approaches.},
  group =	 {tree}
}

@Article{Bishop:hierarchy98,
  author =	 {Christopher M. Bishop and Michael E. Tipping},
  title =	 {A Hierarchical Latent Variable Model for Data
                  Visualisation},
  journal =	 PAMI,
  year =	 1998,
  OPTkey =	 {},
  volume =	 20,
  number =	 3,
  pages =	 {281--293},
  OPTmonth =	 {},
  OPTnote =	 {},
  doi =		 {10.1109/34.667885},
  OPTpubmedid =	 {},
  linkpdf =
                  {ftp://ftp.research.microsoft.com/users/mtipping/Bishop-hierarchical98.pdf},
  linksoftware = {http://www.ncrg.aston.ac.uk/PhiVis/Welcome.html},
  abstract =	 {Visualization has proven to be a powerful and
                  widely-applicable tool for the analysis and
                  interpretation of multivariate data. Most
                  visualization algorithms aim to find a projection
                  from the data space down to a two-dimensional
                  visualization space. However, for complex data sets
                  living in a high-dimensional space, it is unlikely
                  that a single two-dimensional projection can reveal
                  all of the interesting structure. We therefore
                  introduce a hierarchical visualization algorithm
                  which allows the complete data set to be visualized
                  at the top level, with clusters and subclusters of
                  data points visualized at deeper levels. The
                  algorithm is based on a hierarchical mixture of
                  latent variable models, whose parameters are
                  estimated using the expectation-maximization
                  algorithm. We demonstrate the principle of the
                  approach on a toy data set, and we then apply the
                  algorithm to the visualization of a synthetic data
                  set in 12 dimensions obtained from a simulation of
                  multiphase flows in oil pipelines, and to data in 36
                  dimensions derived from satellite images. A Matlab
                  software implementation of the algorithm is publicly
                  available from the World Wide Web.},
  group =	 {pca, hierarchical models, ppca}
}

@InProceedings{Felzenszwalb:efficient00,
  author =	 {Pedro F. Felzenszwalb and Daniel P. Huttenlocher},
  title =	 {Efficient Matching of Pictorial Structures},
  OPTcrossref =	 {},
  OPTkey =	 {},
  booktitle =	 pCVPR,
  pages =	 {66--73},
  year =	 2000,
  OPTeditor =	 {},
  volume =	 2,
  OPTnumber =	 {},
  OPTseries =	 {},
  address =	 {Hilton Head Island, South Carolina, U.S.A.},
  month =	 {13--15 Jun.},
  OPTorganization ={},
  publisher =	 ieeecomp,
  OPTpublisher = {},
  OPTnote =	 {},
  doi =		 {10.1109/CVPR.2000.854739},
  OPTpubmedid =	 {},
  linkps =
                  {http://people.cs.uchicago.edu/~pff/papers/blobrec2.ps.gz},
  OPTlinksoftware ={},
  abstract =	 {A pictorial structure is a collection of parts
                  arranged in a deformable configuration. Each part is
                  represented using a simple appearance model and the
                  deformable configuration is represented by
                  spring-like connections between pairs of
                  parts. While pictorial structures were introduced a
                  number of years ago, they have not been broadly
                  applied to matching and recognition problems. This
                  has been due in part to the computational difficulty
                  of matching pictorial structures to images. In this
                  paper we present an efficient algorithm for finding
                  the best global match of a pictorial stucture to an
                  image. With this improved algorithm, pictorial
                  structures provide a practical and powerful
                  framework for quantitative descriptions of objects
                  and scenes, and are suitable for many generic image
                  recognition problems. We illustrate the approach
                  using simple models of a person and a car.},
  group =	 {tree}
}

@Article{Feng:combining02,
  author =	 {Xiaojuan Feng and Christopher K. I. Williams and
                  Stephen N. Felderhof},
  title =	 {Combining Belief Networks and Neural Networks for
                  Scene Segmentation},
  journal =	 PAMI,
  year =	 2002,
  OPTkey =	 {},
  volume =	 24,
  number =	 4,
  pages =	 {467--483},
  OPTmonth =	 {},
  doi =		 {10.1109/34.993555},
  OPTannote =	 {},
  OPTpubmedid =	 {},
  linkpsgz =
                  {http://www.dai.ed.ac.uk/homes/ckiw/postscript/final7.ps.gz},
  linksoftware = {http://www.dai.ed.ac.uk/homes/ckiw/code/cbn.html},
  abstract =	 {We are concerned with the problem of image
                  segmentation, in which each pixel is assigned to one
                  of a predefined finite number of labels. In Bayesian
                  image analysis, this requires fusing together local
                  predictions for the class labels with a prior model
                  of label images. Following the work of, we consider
                  the use of tree-structured belief networks (TSBNs)
                  as prior models. The parameters in the TSBN are
                  trained using a maximum-likelihood objective
                  function with the EM algorithm and the resulting
                  model is evaluated by calculating how efficiently it
                  codes label images. A number of authors have used
                  Gaussian mixture models to connect the label field
                  to the image data. In this paper, we compare this
                  approach to the scaled-likelihood method of where
                  local predictions of pixel classification from
                  neural networks are fused with the TSBN prior. Our
                  results show a higher performance is obtained with
                  the neural networks. We evaluate the classification
                  results obtained and emphasize not only the maximum
                  a posteriori segmentation, but also the uncertainty,
                  as evidenced e.g., by the pixelwise posterior
                  marginal entropies. We also investigate the use of
                  conditional maximum-likelihood training for the TSBN
                  and find that this gives rise to improved
                  classification performance over the ML-trained
                  TSBN.},
  group =	 {tree, image segmentation}
}

@InProceedings{Grochow:styleik04,
  author =	 {Keith Grochow and Steven L. Martin and Aaron
                  Hertzmann and Zoran Popovic},
  title =	 {Style-Based Inverse Kinematics},
  OPTcrossref =	 {},
  booktitle =	 {ACM Transactions on Graphics (SIGGRAPH 2004)},
  pages =	 {522--531},
  year =	 2004,
  doi =		 {10.1145/1186562.1015755},
  linkpdf =
                  {http://grail.cs.washington.edu/projects/styleik/styleik.pdf},
  label1 =	 {Web page},
  link1 =	 {http://grail.cs.washington.edu/projects/styleik/},
  abstract =	 {This paper presents an inverse kinematics system
                  based on a learned model of human poses. Given a set
                  of constraints, our system can produce the most
                  likely pose satisfying those constraints, in real
                  time. Training the model on different input data
                  leads to different styles of IK. The model is
                  represented as a probability distribution over the
                  space of all possible poses. This means that our IK
                  system can generate any pose, but prefers poses that
                  are most similar to the space of poses in the
                  training data. We represent the probability with a
                  novel model called a Scaled Gaussian Process Latent
                  Variable Model. The parameters of the model are all
                  learned automatically; no manual tuning is required
                  for the learning component of the system. We
                  additionally describe a novel procedure for
                  interpolating between styles.\\\\ Our style-based IK
                  can replace conventional IK, wherever it is used in
                  computer animation and computer vision. We
                  demonstrate our system in the context of a number of
                  applications: interactive character posing,
                  trajectory keyframing, real-time motion capture with
                  missing markers, and posing from a 2D image.},
  group =	 {gplvm}
}

@InProceedings{Ioffe:mixtures01,
  author = 	 {Sergey Ioffe and David A. Forsyth},
  title = 	 {Mixtures of Trees for Object Recognition},
  booktitle =	 pCVPR,
  pages =	 {180--185},
  year =	 2001,
  volume =	 2,
  doi =	 {10.1109/CVPR.2001.990953},
  address =	 {Hawaii, U.S.A.},
  month =	 {11--13 Dec.},
  publisher =	 ieeecomp,
  OPTpubmedid =  {},
  linkpdf =	 {http://http.cs.berkeley.edu/~daf/cvpr.pdf},
  OPTlinksoftware = {},
  abstract =	 {Efficient detection of objects in images is complicated 
                 by variations of object appearance due to intra-class
                 object differences, articulation, lighting,
                 occlusions, and aspect variations. To reduce the
                 search required for detection, we employ the
                 bottom-up approach where we find candidate image
                 features and associate some of them with parts of the
                 object model. We represent objects as collections of
                 local features, and would like to allow any of them
                 to be absent, with only a small subset sufficient for
                 detection; furthermore, our model should allow
                 efficient correspondence search. We propose a model,
                 Mixture of Trees, that achieves these goals. With a
                 mixture of trees, we can model the individual
                 appearances of the features, relationships among
                 them, and the aspect, and handle
                 occlusions. Independences captured in the model make
                 efficient inference possible. In our earlier work, we
                 have shown that mixtures of trees can be used to
                 model objects with a natural tree structure, in the
                 context of human tracking. Now we show that a natural
                 tree structure is not required, and use a mixture of
                 trees for both frontal and view-invariant face
                 detection. We also show that by modeling faces as
                 collections of features we can establish an intrinsic
                 coordinate frame for a face, and estimate the
                 out-of-plane rotation of a face.},
  group =	 {tree}
}
@InProceedings{Lan:beyond05,
  author = 	 {Xiangyang Lan and Daniel P. Huttenlocher},
  title = 	 {Beyond Trees: Common-Factor Models for 2{D} Human Pose Recovery},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 iccv,
  pages =	 {470--477},
  year =	 2005,
  OPTeditor = 	 {},
  volume =	 1,
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Bejing, China},
  month =	 {17--21 Oct.},
  OPTorganization = {},
  publisher =	 ieeecomp,
  doi =		 {10.1109/ICCV.2005.48},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  linkpdf =	 {http://www.cs.cornell.edu/~dph/papers/lan-pose-iccv05.pdf},
  OPTlinksoftware = {},
  abstract =	 {Tree structured models have been widely used for determining
                  the pose of a human body, from either 2D or 3D
                  data. While such models can effectively represent
                  the kinematic constraints of the skeletal structure,
                  they do not capture additional constraints such as
                  coordination of the limbs. Tree structured models
                  thus miss an important source of information about
                  human body pose, as limb coordination is necessary
                  for balance while standing, walking, or running, as
                  well as being evident in other activities such as
                  dancing and throwing. In this paper, we consider the
                  use of undirected graphical models that augment a
                  tree structure with latent variables in order to
                  account for coordination between limbs. We refer to
                  these as common-factor models, since they are
                  constructed by using factor analysis to identify
                  additional correlations in limb position that are
                  not accounted for by the kinematic tree
                  structure. These common-factor models have an
                  underlying tree structure and thus a variant of the
                  standard Viterbi algorithm for a tree can be applied
                  for efficient estimation. We present some
                  experimental results contrasting common-factor
                  models with tree models, and quantify the
                  improvement in pose estimation for 2D image data.},
  group =	 {tree, human pose}
}
@InProceedings{Ramanan:finding03,
  author = 	 {Deva Ramanan and David A. Forsyth},
  title = 	 {Finding and Tracking People from the Bottom Up},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  pages =	 {467--474},
  year =	 2003,
  OPTeditor = 	 {},
  volume =	 2,
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Madison, Wisconsin, U.S.A.},
  month =	 {18--20 Jun.},
  OPTorganization = {},
  publisher =	 ieeecomp,
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  linkpdf =	 {http://www.eecs.berkeley.edu/Research/Projects/CS/vision/human/ramanan-cvpr03.pdf},
  OPTlinksoftware = {},
  abstract =	 {We describe a tracker that can track moving people in 
                 long sequences without manual initialization. Moving
                 people are modeled with the assumption that, while
                 configuration can vary quite substantially from frame
                 to frame, appearance does not. This leads to an
                 algorithm that firstly builds a model of the
                 appearance of the body of each individual by
                 clustering candidate body segments, and then uses
                 this model to find all individuals in each
                 frame. Unusually, the tracker does not rely on a
                 model of human dynamics to identify possible
                 instances of people; such models are unreliable,
                 because human motion is fast and large accelerations
                 are common. We show our tracking algorithm can be
                 interpreted as a loopy inference procedure on an
                 underlying Bayes net. Experiments on video of real
                 scenes demonstrate that this tracker can (a) count
                 distinct individuals; (b) identify and track them;
                 (c) recover when it loses track, for example, if
                 individuals are occluded or briefly leave the view;
                 (d) identify the configuration of the body largely
                 correctly; and (e) is not dependent on particular
                 models of human motion.},
  group =	 {tracking, pose estimation, tree}
}
@InProceedings{Sigal:loose04,
  author = 	 {Leonid Sigal and Sidharth Bhatia and Stefan Roth and Michael J. Black and Michael Isard},
  title = 	 {Tracking Loose-Limbed People},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  pages =	 {421--428},
  year =	 2004,
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Washington, DC, U.S.A.},
  month =	 {29 Jun.--1 Jul.},
  OPTorganization = {},
  publisher =	 ieeecomp,
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  linkpdf =	 {http://research.microsoft.com/research/sv/sv-pubs/looselimbed.pdf},
  OPTlinksoftware = {},
  abstract =	 {We pose the problem of 3D human tracking as one of inference 
                 in a graphical model. Unlike traditional kinematic
                 tree representations, our model of the body is a
                 collection of loosely-connected limbs. Conditional
                 probabilities relating the 3D pose of connected limbs
                 are learned from motion-captured training
                 data. Similarly, we learn probabilistic models for
                 the temporal evolution of each limb (forward and
                 backward in time). Human pose and motion estimation
                 is then solved with non-parametric belief propagation
                 using a variation of particle filtering that can be
                 applied over a general loopy graph. The loose-limbed
                 model and decentralized graph structure facilitate
                 the use of low-level visual cues. We adopt simple
                 limb and head detectors to provide "bottom-up"
                 information that is incorporated into the inference
                 process at every time-step; these detectors permit
                 automatic initialization and aid recovery from
                 transient tracking failures. We illustrate the method
                 by automatically tracking a walking person in video
                 imagery using four calibrated cameras. Our
                 experimental apparatus includes a marker-based motion
                 capture system aligned with the coordinate frame of
                 the calibrated cameras with which we quantitatively
                 evaluate the accuracy of our 3D person tracker.},
  group =	 {tracking, pose estimation, tree}
}
@Article{Tipping:probpca99,
  author = 	 {Michael E. Tipping and Christopher M. Bishop},
  title = 	 {Probabilistic Principal Component Analysis},
  journal = 	 JRSSb,
  year = 	 1999,
  volume =	 6,
  number =	 3,
  doi = 	 {doi:10.1111/1467-9868.00196},
  pages =	 {611--622},
  abstract =	 {Principal component analysis (PCA) is a ubiquitous 
                 technique for data analysis and processing, but one
                 which is not based upon a probability model. In this
                 paper we demonstrate how the principal axes of a set
                 of observed data vectors may be determined through
                 maximum-likelihood estimation of parameters in a
                 latent variable model closely related to factor
                 analysis. We consider the properties of the
                 associated likelihood function, giving an EM
                 algorithm for estimating the principal subspace
                 iteratively, and discuss, with illustrative examples,
                 the advantages conveyed by this probabilistic
                 approach to PCA},
  linkps = 	 {http://www.gatsby.ucl.ac.uk/~quaid/course/readings/ppca.ps}
}
@InProceedings{Urtasun:3dpeople06,
  author = 	 {Raquel Urtasun and David J. Fleet and Pascal Fua},
  title = 	 {3{D} People Tracking with {G}aussian Process Dynamical Models},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 pCVPR,
  pages =	 {238--245},
  year =	 {2006},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {New York, U.S.A.},
  month =	 {17--22 Jun.},
  OPTorganization = {},
  publisher =	 ieeecomp,
  OPTpublisher = {},
  doi =	 {10.1109/CVPR.2006.15},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  OPTlinkpdf = 	 {},
  OPTlinksoftware = {},
  OPTabstract =  {},
  group =	 {gplvm,tracking}
}
@InProceedings{Wang:gpdm05,
  author = 	 {Jack M. Wang and David J. Fleet and Aaron Hertzmann},
  title = 	 {Gaussian Process Dynamical Models},
  crossref =	 {Weiss:nips05},
  OPTpages = 	 {},
  linkpdf = 	 {http://www.cs.toronto.edu/~fleet/research/Papers/NIPS2005.pdf},
  label2 =  	 {Web-page},
  link2 =  	 {http://www.dgp.toronto.edu/~jmwang/gpdm/},
  abstract =  	 {This paper introduces Gaussian Process Dynamical Models (GPDM) 
                 for nonlinear time series analysis. A GPDM comprises
                 a low-dimensional latent space with associated
                 dynamics, and a map from the latent space to an
                 observation space. We marginalize out the model
                 parameters in closed form, which amounts to using
                 Gaussian Process (GP) priors for both the dynamics
                 and the observation mappings. This results in a
                 nonparameteric model for dynamical systems that
                 accounts for uncertainty in the model. We demonstrate
                 the approach on human motion capture data in which
                 each pose is 62-dimensional. Despite the use of small
                 data sets, the GPDM leans an effective representation
                 of the nonlinear dynamics in these spaces.},
   group = 	 {gplvm}
}
@InProceedings{Williams:tree98,
  author = 	 {Christopher K. I. Williams and Xiaojuan Feng},
  title = 	 {Tree-structured Belief Networks as Models of Images},
  booktitle = 	 {Proceedings Ninth International Conference on
                 Artificial Neural Networks, ICANN'99},
  OPTkey = 	 {},
  OPTbooktitle = {},
  OPTpages = 	 {},
  year =	 1999,
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  OPTannote = 	 {},
  OPTpubmedid =  {},
  linkpsgz =	 {http://www.dai.ed.ac.uk/homes/ckiw/postscript/coding6.ps.gz},
  OPTlinksoftware = {},
  abstract =	 {In this paper we are concerned with using a tree-structured 
                 belief network (TSBN) as a prior model in segmenting
                 a natural image into a number of predefined
                 classes. The TSBN was trained by the EM algorithm
                 based on a set of training label images. The average
                 log likelihood (or bit rate) of a test set of images
                 shows that the learned TSBN is a better model for
                 images than models based upon independent blocks of
                 varying sizes. We also analyze the relative
                 advanteges obtained by modelling correlations at
                 different length scales in the tree.},
  group =	 {tree}
}
@string{icml =     {Proceedings of the International Conference in 
                   Machine Learning}}
@string{nips =     {Advances in Neural Information Processing Systems}}
@Proceedings{Cohen:icml06,
  title = 	 icml,
  year = 	 2006,
  editor =	 {William Cohen and Andrew Moore},
  booktitle =    icml,
  volume =	 23,
  ISBN = 	 {1-59593-383-2},
  publisher =	 {Omnipress}
}
@Proceedings{Weiss:nips05,
  title = 	 nips,
  year = 	 2006,
  booktitle =	 nips,
  editor =	 {Yair Weiss and Bernhard Sch\"olkopf and John C. Platt},
  volume =	 18,
  address =	 {Cambridge, MA},
  publisher =	 mit
}
